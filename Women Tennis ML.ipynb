{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c212c100",
   "metadata": {},
   "source": [
    "# Women Tennis\n",
    "\n",
    "## Data Scientists: Paolo Hilado and Alison Danvers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ef23b",
   "metadata": {},
   "source": [
    "# Business Problem\n",
    "\n",
    "Data Scientists are tasked with predicting the players who are likely to win each match based on match play statistics. These include first serve percentage, first serve won, second serve percentage, second serve won, ace, double faults, winner, unforced errors, break points created, break points won, net points attempted and net points won. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacaf086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7ce8e",
   "metadata": {},
   "source": [
    "# Data cleaning has been done separately on the train and test set after the data split. Split is carried out with 80% train and 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used to do data split with 80% train and 20% test.\n",
    "# train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e8eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean train set.\n",
    "train = pd.read_excel(\"WTtrain_clean.xlsx\")\n",
    "# Load the clean test set.\n",
    "test = pd.read_excel(\"WTtest_clean.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f94c522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>FSP.1</th>\n",
       "      <th>FSW.1</th>\n",
       "      <th>SSP.1</th>\n",
       "      <th>SSW.1</th>\n",
       "      <th>ACE.1</th>\n",
       "      <th>DBF.1</th>\n",
       "      <th>WNR.1</th>\n",
       "      <th>UFE.1</th>\n",
       "      <th>BPC.1</th>\n",
       "      <th>...</th>\n",
       "      <th>SSP.2</th>\n",
       "      <th>SSW.2</th>\n",
       "      <th>ACE.2</th>\n",
       "      <th>DBF.2</th>\n",
       "      <th>WNR.2</th>\n",
       "      <th>UFE.2</th>\n",
       "      <th>BPC.2</th>\n",
       "      <th>BPW.2</th>\n",
       "      <th>NPA.2</th>\n",
       "      <th>NPW.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>42</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38</td>\n",
       "      <td>55</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result  FSP.1  FSW.1  SSP.1  SSW.1  ACE.1  DBF.1  WNR.1  UFE.1  BPC.1  ...  \\\n",
       "0       1     75     42     25     12    1.0    1.0     13     15    5.0  ...   \n",
       "1       0     58     22     42      8    3.0    6.0     17     35    5.0  ...   \n",
       "2       0     65     43     35     18    1.0    2.0     15     37   15.0  ...   \n",
       "3       0     58     15     42      8    3.0    2.0     15     10    4.0  ...   \n",
       "4       1     48     26     52     20    4.0    6.0     28     27    5.0  ...   \n",
       "\n",
       "   SSP.2  SSW.2  ACE.2  DBF.2  WNR.2  UFE.2  BPC.2  BPW.2  NPA.2  NPW.2  \n",
       "0     47     13    4.0    3.0     32     41   10.0    2.0   29.0   19.0  \n",
       "1     49     16    0.0    0.0     14     23   16.0    5.0   17.0   12.0  \n",
       "2     42     26    6.0    6.0     38     55    9.0    4.0   19.0   13.0  \n",
       "3     25      5    4.0    2.0     24      9    5.0    3.0   13.0   11.0  \n",
       "4     40     15    3.0    8.0     32     40    4.0   12.0   12.0   16.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few records for the train set.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "444f9b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>FSP.1</th>\n",
       "      <th>FSW.1</th>\n",
       "      <th>SSP.1</th>\n",
       "      <th>SSW.1</th>\n",
       "      <th>ACE.1</th>\n",
       "      <th>DBF.1</th>\n",
       "      <th>WNR.1</th>\n",
       "      <th>UFE.1</th>\n",
       "      <th>BPC.1</th>\n",
       "      <th>...</th>\n",
       "      <th>SSP.2</th>\n",
       "      <th>SSW.2</th>\n",
       "      <th>ACE.2</th>\n",
       "      <th>DBF.2</th>\n",
       "      <th>WNR.2</th>\n",
       "      <th>UFE.2</th>\n",
       "      <th>BPC.2</th>\n",
       "      <th>BPW.2</th>\n",
       "      <th>NPA.2</th>\n",
       "      <th>NPW.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result  FSP.1  FSW.1  SSP.1  SSW.1  ACE.1  DBF.1  WNR.1  UFE.1  BPC.1  ...  \\\n",
       "0       1     62     26     38     10    1.0      5     20     12      8  ...   \n",
       "1       1     80     25     20      8    0.0      0     12     18     10  ...   \n",
       "2       0     57     14     43      5    2.0      5     12     32      0  ...   \n",
       "3       0     61     15     39     11    2.0      4     23     35      6  ...   \n",
       "4       1     71     20     29      5    4.0      2     16     15      1  ...   \n",
       "\n",
       "   SSP.2  SSW.2  ACE.2  DBF.2  WNR.2  UFE.2  BPC.2  BPW.2  NPA.2  NPW.2  \n",
       "0     40     14    0.0      2     24     18      7      4   27.0   19.0  \n",
       "1     42      6    2.0      2     14     35      4      3    9.0    5.0  \n",
       "2     43     11    7.0      2     14      4      5      6    2.0    4.0  \n",
       "3     40      9    3.0      4     14     22      8      9    4.0    6.0  \n",
       "4     42      9    0.0      1     15      9      1      6    4.0    6.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first few records for the test set.\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e51fa35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361, 25)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the shape of the train set.\n",
    "train.shape # 361 records (80%) and 25 features; 24 explanatory and 1 response variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fdce973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 25)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the shape of the test set\n",
    "test.shape # 91 records (20%) and 25 features; 24 explanatory and 1 response variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83ee359b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result    False\n",
       "FSP.1     False\n",
       "FSW.1     False\n",
       "SSP.1     False\n",
       "SSW.1     False\n",
       "ACE.1     False\n",
       "DBF.1     False\n",
       "WNR.1     False\n",
       "UFE.1     False\n",
       "BPC.1     False\n",
       "BPW.1     False\n",
       "NPA.1     False\n",
       "NPW.1     False\n",
       "FSP.2     False\n",
       "FSW.2     False\n",
       "SSP.2     False\n",
       "SSW.2     False\n",
       "ACE.2     False\n",
       "DBF.2     False\n",
       "WNR.2     False\n",
       "UFE.2     False\n",
       "BPC.2     False\n",
       "BPW.2     False\n",
       "NPA.2     False\n",
       "NPW.2     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that there are no missing cases for the train set.\n",
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49807e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result    False\n",
       "FSP.1     False\n",
       "FSW.1     False\n",
       "SSP.1     False\n",
       "SSW.1     False\n",
       "ACE.1     False\n",
       "DBF.1     False\n",
       "WNR.1     False\n",
       "UFE.1     False\n",
       "BPC.1     False\n",
       "BPW.1     False\n",
       "NPA.1     False\n",
       "NPW.1     False\n",
       "FSP.2     False\n",
       "FSW.2     False\n",
       "SSP.2     False\n",
       "SSW.2     False\n",
       "ACE.2     False\n",
       "DBF.2     False\n",
       "WNR.2     False\n",
       "UFE.2     False\n",
       "BPC.2     False\n",
       "BPW.2     False\n",
       "NPA.2     False\n",
       "NPW.2     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check that there are no missing cases for the test set.\n",
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab55709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Result', 'FSP.1', 'FSW.1', 'SSP.1', 'SSW.1', 'ACE.1', 'DBF.1', 'WNR.1',\n",
       "       'UFE.1', 'BPC.1', 'BPW.1', 'NPA.1', 'NPW.1', 'FSP.2', 'FSW.2', 'SSP.2',\n",
       "       'SSW.2', 'ACE.2', 'DBF.2', 'WNR.2', 'UFE.2', 'BPC.2', 'BPW.2', 'NPA.2',\n",
       "       'NPW.2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fd4a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>FSP.1</th>\n",
       "      <th>FSW.1</th>\n",
       "      <th>SSP.1</th>\n",
       "      <th>SSW.1</th>\n",
       "      <th>ACE.1</th>\n",
       "      <th>DBF.1</th>\n",
       "      <th>WNR.1</th>\n",
       "      <th>UFE.1</th>\n",
       "      <th>BPC.1</th>\n",
       "      <th>...</th>\n",
       "      <th>SSP.2</th>\n",
       "      <th>SSW.2</th>\n",
       "      <th>ACE.2</th>\n",
       "      <th>DBF.2</th>\n",
       "      <th>WNR.2</th>\n",
       "      <th>UFE.2</th>\n",
       "      <th>BPC.2</th>\n",
       "      <th>BPW.2</th>\n",
       "      <th>NPA.2</th>\n",
       "      <th>NPW.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.443518</td>\n",
       "      <td>1.425362</td>\n",
       "      <td>-1.456902</td>\n",
       "      <td>0.089555</td>\n",
       "      <td>-0.707642</td>\n",
       "      <td>-0.956503</td>\n",
       "      <td>-0.698982</td>\n",
       "      <td>-0.74668</td>\n",
       "      <td>-0.143944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003051</td>\n",
       "      <td>0.301452</td>\n",
       "      <td>0.559971</td>\n",
       "      <td>-0.166887</td>\n",
       "      <td>0.982264</td>\n",
       "      <td>1.260251</td>\n",
       "      <td>1.088966</td>\n",
       "      <td>-0.980832</td>\n",
       "      <td>1.892277</td>\n",
       "      <td>1.055519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.611904</td>\n",
       "      <td>-0.547249</td>\n",
       "      <td>0.598502</td>\n",
       "      <td>-0.689465</td>\n",
       "      <td>0.102824</td>\n",
       "      <td>1.157737</td>\n",
       "      <td>-0.300195</td>\n",
       "      <td>0.91312</td>\n",
       "      <td>-0.143944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.215241</td>\n",
       "      <td>0.897205</td>\n",
       "      <td>-0.952558</td>\n",
       "      <td>-1.345102</td>\n",
       "      <td>-0.583671</td>\n",
       "      <td>-0.098261</td>\n",
       "      <td>2.622981</td>\n",
       "      <td>-0.287373</td>\n",
       "      <td>0.609678</td>\n",
       "      <td>0.157016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.234446</td>\n",
       "      <td>1.523993</td>\n",
       "      <td>-0.247841</td>\n",
       "      <td>1.258084</td>\n",
       "      <td>-0.707642</td>\n",
       "      <td>-0.533655</td>\n",
       "      <td>-0.499588</td>\n",
       "      <td>1.07910</td>\n",
       "      <td>2.381027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472577</td>\n",
       "      <td>2.883049</td>\n",
       "      <td>1.316235</td>\n",
       "      <td>1.011329</td>\n",
       "      <td>1.504243</td>\n",
       "      <td>2.316871</td>\n",
       "      <td>0.833297</td>\n",
       "      <td>-0.518526</td>\n",
       "      <td>0.823445</td>\n",
       "      <td>0.285373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.611904</td>\n",
       "      <td>-1.237664</td>\n",
       "      <td>0.598502</td>\n",
       "      <td>-0.689465</td>\n",
       "      <td>0.102824</td>\n",
       "      <td>-0.533655</td>\n",
       "      <td>-0.499588</td>\n",
       "      <td>-1.16163</td>\n",
       "      <td>-0.396442</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331034</td>\n",
       "      <td>-1.287223</td>\n",
       "      <td>0.559971</td>\n",
       "      <td>-0.559625</td>\n",
       "      <td>0.286293</td>\n",
       "      <td>-1.154881</td>\n",
       "      <td>-0.189379</td>\n",
       "      <td>-0.749679</td>\n",
       "      <td>0.182146</td>\n",
       "      <td>0.028658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.820976</td>\n",
       "      <td>-0.152727</td>\n",
       "      <td>1.807563</td>\n",
       "      <td>1.647594</td>\n",
       "      <td>0.508056</td>\n",
       "      <td>1.157737</td>\n",
       "      <td>0.796469</td>\n",
       "      <td>0.24920</td>\n",
       "      <td>-0.143944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260388</td>\n",
       "      <td>0.698621</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>1.796805</td>\n",
       "      <td>0.982264</td>\n",
       "      <td>1.184778</td>\n",
       "      <td>-0.445048</td>\n",
       "      <td>1.330699</td>\n",
       "      <td>0.075262</td>\n",
       "      <td>0.670446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result     FSP.1     FSW.1     SSP.1     SSW.1     ACE.1     DBF.1  \\\n",
       "0       1  1.443518  1.425362 -1.456902  0.089555 -0.707642 -0.956503   \n",
       "1       0 -0.611904 -0.547249  0.598502 -0.689465  0.102824  1.157737   \n",
       "2       0  0.234446  1.523993 -0.247841  1.258084 -0.707642 -0.533655   \n",
       "3       0 -0.611904 -1.237664  0.598502 -0.689465  0.102824 -0.533655   \n",
       "4       1 -1.820976 -0.152727  1.807563  1.647594  0.508056  1.157737   \n",
       "\n",
       "      WNR.1    UFE.1     BPC.1  ...     SSP.2     SSW.2     ACE.2     DBF.2  \\\n",
       "0 -0.698982 -0.74668 -0.143944  ...  1.003051  0.301452  0.559971 -0.166887   \n",
       "1 -0.300195  0.91312 -0.143944  ...  1.215241  0.897205 -0.952558 -1.345102   \n",
       "2 -0.499588  1.07910  2.381027  ...  0.472577  2.883049  1.316235  1.011329   \n",
       "3 -0.499588 -1.16163 -0.396442  ... -1.331034 -1.287223  0.559971 -0.559625   \n",
       "4  0.796469  0.24920 -0.143944  ...  0.260388  0.698621  0.181839  1.796805   \n",
       "\n",
       "      WNR.2     UFE.2     BPC.2     BPW.2     NPA.2     NPW.2  \n",
       "0  0.982264  1.260251  1.088966 -0.980832  1.892277  1.055519  \n",
       "1 -0.583671 -0.098261  2.622981 -0.287373  0.609678  0.157016  \n",
       "2  1.504243  2.316871  0.833297 -0.518526  0.823445  0.285373  \n",
       "3  0.286293 -1.154881 -0.189379 -0.749679  0.182146  0.028658  \n",
       "4  0.982264  1.184778 -0.445048  1.330699  0.075262  0.670446  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the explanatory variables (continuous) for the train set.\n",
    "# Assigning feature labels to variable continuous_vars.\n",
    "varz = ['FSP.1', 'FSW.1', 'SSP.1', 'SSW.1', 'ACE.1', 'DBF.1', 'WNR.1',\n",
    "       'UFE.1', 'BPC.1', 'BPW.1', 'NPA.1', 'NPW.1', 'FSP.2', 'FSW.2', 'SSP.2',\n",
    "       'SSW.2', 'ACE.2', 'DBF.2', 'WNR.2', 'UFE.2', 'BPC.2', 'BPW.2', 'NPA.2',\n",
    "       'NPW.2']\n",
    "\n",
    "# Initialize StandardScaler.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to the continuous variables and transform them.\n",
    "train[varz] = scaler.fit_transform(train[varz])\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907a0a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>FSP.1</th>\n",
       "      <th>FSW.1</th>\n",
       "      <th>SSP.1</th>\n",
       "      <th>SSW.1</th>\n",
       "      <th>ACE.1</th>\n",
       "      <th>DBF.1</th>\n",
       "      <th>WNR.1</th>\n",
       "      <th>UFE.1</th>\n",
       "      <th>BPC.1</th>\n",
       "      <th>...</th>\n",
       "      <th>SSP.2</th>\n",
       "      <th>SSW.2</th>\n",
       "      <th>ACE.2</th>\n",
       "      <th>DBF.2</th>\n",
       "      <th>WNR.2</th>\n",
       "      <th>UFE.2</th>\n",
       "      <th>BPC.2</th>\n",
       "      <th>BPW.2</th>\n",
       "      <th>NPA.2</th>\n",
       "      <th>NPW.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.119964</td>\n",
       "      <td>-0.088027</td>\n",
       "      <td>-0.119964</td>\n",
       "      <td>-0.374131</td>\n",
       "      <td>-0.672048</td>\n",
       "      <td>0.678214</td>\n",
       "      <td>-0.050316</td>\n",
       "      <td>-1.220707</td>\n",
       "      <td>0.500154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351212</td>\n",
       "      <td>0.329722</td>\n",
       "      <td>-1.077291</td>\n",
       "      <td>-0.542649</td>\n",
       "      <td>0.288044</td>\n",
       "      <td>-0.505325</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>-0.512142</td>\n",
       "      <td>2.136008</td>\n",
       "      <td>1.312970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.303316</td>\n",
       "      <td>-0.181172</td>\n",
       "      <td>-2.303316</td>\n",
       "      <td>-0.744195</td>\n",
       "      <td>-1.008812</td>\n",
       "      <td>-1.406837</td>\n",
       "      <td>-0.846616</td>\n",
       "      <td>-0.687928</td>\n",
       "      <td>0.931567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564993</td>\n",
       "      <td>-1.074005</td>\n",
       "      <td>-0.271094</td>\n",
       "      <td>-0.542649</td>\n",
       "      <td>-0.712414</td>\n",
       "      <td>0.806316</td>\n",
       "      <td>-0.422076</td>\n",
       "      <td>-0.805254</td>\n",
       "      <td>-0.155870</td>\n",
       "      <td>-0.759285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.486522</td>\n",
       "      <td>-1.205767</td>\n",
       "      <td>0.486522</td>\n",
       "      <td>-1.299291</td>\n",
       "      <td>-0.335284</td>\n",
       "      <td>0.678214</td>\n",
       "      <td>-0.846616</td>\n",
       "      <td>0.555222</td>\n",
       "      <td>-1.225497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671884</td>\n",
       "      <td>-0.196676</td>\n",
       "      <td>1.744396</td>\n",
       "      <td>-0.542649</td>\n",
       "      <td>-0.712414</td>\n",
       "      <td>-1.585501</td>\n",
       "      <td>-0.143750</td>\n",
       "      <td>0.074083</td>\n",
       "      <td>-1.047156</td>\n",
       "      <td>-0.907303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>-1.112622</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.189099</td>\n",
       "      <td>-0.335284</td>\n",
       "      <td>0.261204</td>\n",
       "      <td>0.248297</td>\n",
       "      <td>0.821611</td>\n",
       "      <td>0.068742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351212</td>\n",
       "      <td>-0.547608</td>\n",
       "      <td>0.132004</td>\n",
       "      <td>0.211260</td>\n",
       "      <td>-0.712414</td>\n",
       "      <td>-0.196704</td>\n",
       "      <td>0.691225</td>\n",
       "      <td>0.953421</td>\n",
       "      <td>-0.792503</td>\n",
       "      <td>-0.611266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.211640</td>\n",
       "      <td>-0.646897</td>\n",
       "      <td>-1.211640</td>\n",
       "      <td>-1.299291</td>\n",
       "      <td>0.338244</td>\n",
       "      <td>-0.572816</td>\n",
       "      <td>-0.448466</td>\n",
       "      <td>-0.954318</td>\n",
       "      <td>-1.009791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564993</td>\n",
       "      <td>-0.547608</td>\n",
       "      <td>-1.077291</td>\n",
       "      <td>-0.919604</td>\n",
       "      <td>-0.612368</td>\n",
       "      <td>-1.199724</td>\n",
       "      <td>-1.257051</td>\n",
       "      <td>0.074083</td>\n",
       "      <td>-0.792503</td>\n",
       "      <td>-0.611266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result     FSP.1     FSW.1     SSP.1     SSW.1     ACE.1     DBF.1  \\\n",
       "0       1  0.119964 -0.088027 -0.119964 -0.374131 -0.672048  0.678214   \n",
       "1       1  2.303316 -0.181172 -2.303316 -0.744195 -1.008812 -1.406837   \n",
       "2       0 -0.486522 -1.205767  0.486522 -1.299291 -0.335284  0.678214   \n",
       "3       0 -0.001333 -1.112622  0.001333 -0.189099 -0.335284  0.261204   \n",
       "4       1  1.211640 -0.646897 -1.211640 -1.299291  0.338244 -0.572816   \n",
       "\n",
       "      WNR.1     UFE.1     BPC.1  ...     SSP.2     SSW.2     ACE.2     DBF.2  \\\n",
       "0 -0.050316 -1.220707  0.500154  ...  0.351212  0.329722 -1.077291 -0.542649   \n",
       "1 -0.846616 -0.687928  0.931567  ...  0.564993 -1.074005 -0.271094 -0.542649   \n",
       "2 -0.846616  0.555222 -1.225497  ...  0.671884 -0.196676  1.744396 -0.542649   \n",
       "3  0.248297  0.821611  0.068742  ...  0.351212 -0.547608  0.132004  0.211260   \n",
       "4 -0.448466 -0.954318 -1.009791  ...  0.564993 -0.547608 -1.077291 -0.919604   \n",
       "\n",
       "      WNR.2     UFE.2     BPC.2     BPW.2     NPA.2     NPW.2  \n",
       "0  0.288044 -0.505325  0.412900 -0.512142  2.136008  1.312970  \n",
       "1 -0.712414  0.806316 -0.422076 -0.805254 -0.155870 -0.759285  \n",
       "2 -0.712414 -1.585501 -0.143750  0.074083 -1.047156 -0.907303  \n",
       "3 -0.712414 -0.196704  0.691225  0.953421 -0.792503 -0.611266  \n",
       "4 -0.612368 -1.199724 -1.257051  0.074083 -0.792503 -0.611266  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize the explanatory variables (continuous) for the train set.\n",
    "# Assigning feature labels to variable continuous_vars.\n",
    "varz = ['FSP.1', 'FSW.1', 'SSP.1', 'SSW.1', 'ACE.1', 'DBF.1', 'WNR.1',\n",
    "       'UFE.1', 'BPC.1', 'BPW.1', 'NPA.1', 'NPW.1', 'FSP.2', 'FSW.2', 'SSP.2',\n",
    "       'SSW.2', 'ACE.2', 'DBF.2', 'WNR.2', 'UFE.2', 'BPC.2', 'BPW.2', 'NPA.2',\n",
    "       'NPW.2']\n",
    "\n",
    "# Initialize StandardScaler.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler to the continuous variables and transform them.\n",
    "test[varz] = scaler.fit_transform(test[varz])\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "592de8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>FSP.1</th>\n",
       "      <th>FSW.1</th>\n",
       "      <th>SSP.1</th>\n",
       "      <th>SSW.1</th>\n",
       "      <th>ACE.1</th>\n",
       "      <th>DBF.1</th>\n",
       "      <th>WNR.1</th>\n",
       "      <th>UFE.1</th>\n",
       "      <th>BPC.1</th>\n",
       "      <th>...</th>\n",
       "      <th>SSP.2</th>\n",
       "      <th>SSW.2</th>\n",
       "      <th>ACE.2</th>\n",
       "      <th>DBF.2</th>\n",
       "      <th>WNR.2</th>\n",
       "      <th>UFE.2</th>\n",
       "      <th>BPC.2</th>\n",
       "      <th>BPW.2</th>\n",
       "      <th>NPA.2</th>\n",
       "      <th>NPW.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.443518</td>\n",
       "      <td>1.425362</td>\n",
       "      <td>-1.456902</td>\n",
       "      <td>0.089555</td>\n",
       "      <td>-0.707642</td>\n",
       "      <td>-0.956503</td>\n",
       "      <td>-0.698982</td>\n",
       "      <td>-0.74668</td>\n",
       "      <td>-0.143944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003051</td>\n",
       "      <td>0.301452</td>\n",
       "      <td>0.559971</td>\n",
       "      <td>-0.166887</td>\n",
       "      <td>0.982264</td>\n",
       "      <td>1.260251</td>\n",
       "      <td>1.088966</td>\n",
       "      <td>-0.980832</td>\n",
       "      <td>1.892277</td>\n",
       "      <td>1.055519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.611904</td>\n",
       "      <td>-0.547249</td>\n",
       "      <td>0.598502</td>\n",
       "      <td>-0.689465</td>\n",
       "      <td>0.102824</td>\n",
       "      <td>1.157737</td>\n",
       "      <td>-0.300195</td>\n",
       "      <td>0.91312</td>\n",
       "      <td>-0.143944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.215241</td>\n",
       "      <td>0.897205</td>\n",
       "      <td>-0.952558</td>\n",
       "      <td>-1.345102</td>\n",
       "      <td>-0.583671</td>\n",
       "      <td>-0.098261</td>\n",
       "      <td>2.622981</td>\n",
       "      <td>-0.287373</td>\n",
       "      <td>0.609678</td>\n",
       "      <td>0.157016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.234446</td>\n",
       "      <td>1.523993</td>\n",
       "      <td>-0.247841</td>\n",
       "      <td>1.258084</td>\n",
       "      <td>-0.707642</td>\n",
       "      <td>-0.533655</td>\n",
       "      <td>-0.499588</td>\n",
       "      <td>1.07910</td>\n",
       "      <td>2.381027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472577</td>\n",
       "      <td>2.883049</td>\n",
       "      <td>1.316235</td>\n",
       "      <td>1.011329</td>\n",
       "      <td>1.504243</td>\n",
       "      <td>2.316871</td>\n",
       "      <td>0.833297</td>\n",
       "      <td>-0.518526</td>\n",
       "      <td>0.823445</td>\n",
       "      <td>0.285373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.611904</td>\n",
       "      <td>-1.237664</td>\n",
       "      <td>0.598502</td>\n",
       "      <td>-0.689465</td>\n",
       "      <td>0.102824</td>\n",
       "      <td>-0.533655</td>\n",
       "      <td>-0.499588</td>\n",
       "      <td>-1.16163</td>\n",
       "      <td>-0.396442</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331034</td>\n",
       "      <td>-1.287223</td>\n",
       "      <td>0.559971</td>\n",
       "      <td>-0.559625</td>\n",
       "      <td>0.286293</td>\n",
       "      <td>-1.154881</td>\n",
       "      <td>-0.189379</td>\n",
       "      <td>-0.749679</td>\n",
       "      <td>0.182146</td>\n",
       "      <td>0.028658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.820976</td>\n",
       "      <td>-0.152727</td>\n",
       "      <td>1.807563</td>\n",
       "      <td>1.647594</td>\n",
       "      <td>0.508056</td>\n",
       "      <td>1.157737</td>\n",
       "      <td>0.796469</td>\n",
       "      <td>0.24920</td>\n",
       "      <td>-0.143944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260388</td>\n",
       "      <td>0.698621</td>\n",
       "      <td>0.181839</td>\n",
       "      <td>1.796805</td>\n",
       "      <td>0.982264</td>\n",
       "      <td>1.184778</td>\n",
       "      <td>-0.445048</td>\n",
       "      <td>1.330699</td>\n",
       "      <td>0.075262</td>\n",
       "      <td>0.670446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result     FSP.1     FSW.1     SSP.1     SSW.1     ACE.1     DBF.1  \\\n",
       "0       1  1.443518  1.425362 -1.456902  0.089555 -0.707642 -0.956503   \n",
       "1       0 -0.611904 -0.547249  0.598502 -0.689465  0.102824  1.157737   \n",
       "2       0  0.234446  1.523993 -0.247841  1.258084 -0.707642 -0.533655   \n",
       "3       0 -0.611904 -1.237664  0.598502 -0.689465  0.102824 -0.533655   \n",
       "4       1 -1.820976 -0.152727  1.807563  1.647594  0.508056  1.157737   \n",
       "\n",
       "      WNR.1    UFE.1     BPC.1  ...     SSP.2     SSW.2     ACE.2     DBF.2  \\\n",
       "0 -0.698982 -0.74668 -0.143944  ...  1.003051  0.301452  0.559971 -0.166887   \n",
       "1 -0.300195  0.91312 -0.143944  ...  1.215241  0.897205 -0.952558 -1.345102   \n",
       "2 -0.499588  1.07910  2.381027  ...  0.472577  2.883049  1.316235  1.011329   \n",
       "3 -0.499588 -1.16163 -0.396442  ... -1.331034 -1.287223  0.559971 -0.559625   \n",
       "4  0.796469  0.24920 -0.143944  ...  0.260388  0.698621  0.181839  1.796805   \n",
       "\n",
       "      WNR.2     UFE.2     BPC.2     BPW.2     NPA.2     NPW.2  \n",
       "0  0.982264  1.260251  1.088966 -0.980832  1.892277  1.055519  \n",
       "1 -0.583671 -0.098261  2.622981 -0.287373  0.609678  0.157016  \n",
       "2  1.504243  2.316871  0.833297 -0.518526  0.823445  0.285373  \n",
       "3  0.286293 -1.154881 -0.189379 -0.749679  0.182146  0.028658  \n",
       "4  0.982264  1.184778 -0.445048  1.330699  0.075262  0.670446  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4ceb4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>FSP.1</th>\n",
       "      <th>FSW.1</th>\n",
       "      <th>SSP.1</th>\n",
       "      <th>SSW.1</th>\n",
       "      <th>ACE.1</th>\n",
       "      <th>DBF.1</th>\n",
       "      <th>WNR.1</th>\n",
       "      <th>UFE.1</th>\n",
       "      <th>BPC.1</th>\n",
       "      <th>...</th>\n",
       "      <th>SSP.2</th>\n",
       "      <th>SSW.2</th>\n",
       "      <th>ACE.2</th>\n",
       "      <th>DBF.2</th>\n",
       "      <th>WNR.2</th>\n",
       "      <th>UFE.2</th>\n",
       "      <th>BPC.2</th>\n",
       "      <th>BPW.2</th>\n",
       "      <th>NPA.2</th>\n",
       "      <th>NPW.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.119964</td>\n",
       "      <td>-0.088027</td>\n",
       "      <td>-0.119964</td>\n",
       "      <td>-0.374131</td>\n",
       "      <td>-0.672048</td>\n",
       "      <td>0.678214</td>\n",
       "      <td>-0.050316</td>\n",
       "      <td>-1.220707</td>\n",
       "      <td>0.500154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351212</td>\n",
       "      <td>0.329722</td>\n",
       "      <td>-1.077291</td>\n",
       "      <td>-0.542649</td>\n",
       "      <td>0.288044</td>\n",
       "      <td>-0.505325</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>-0.512142</td>\n",
       "      <td>2.136008</td>\n",
       "      <td>1.312970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.303316</td>\n",
       "      <td>-0.181172</td>\n",
       "      <td>-2.303316</td>\n",
       "      <td>-0.744195</td>\n",
       "      <td>-1.008812</td>\n",
       "      <td>-1.406837</td>\n",
       "      <td>-0.846616</td>\n",
       "      <td>-0.687928</td>\n",
       "      <td>0.931567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564993</td>\n",
       "      <td>-1.074005</td>\n",
       "      <td>-0.271094</td>\n",
       "      <td>-0.542649</td>\n",
       "      <td>-0.712414</td>\n",
       "      <td>0.806316</td>\n",
       "      <td>-0.422076</td>\n",
       "      <td>-0.805254</td>\n",
       "      <td>-0.155870</td>\n",
       "      <td>-0.759285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.486522</td>\n",
       "      <td>-1.205767</td>\n",
       "      <td>0.486522</td>\n",
       "      <td>-1.299291</td>\n",
       "      <td>-0.335284</td>\n",
       "      <td>0.678214</td>\n",
       "      <td>-0.846616</td>\n",
       "      <td>0.555222</td>\n",
       "      <td>-1.225497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671884</td>\n",
       "      <td>-0.196676</td>\n",
       "      <td>1.744396</td>\n",
       "      <td>-0.542649</td>\n",
       "      <td>-0.712414</td>\n",
       "      <td>-1.585501</td>\n",
       "      <td>-0.143750</td>\n",
       "      <td>0.074083</td>\n",
       "      <td>-1.047156</td>\n",
       "      <td>-0.907303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>-1.112622</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.189099</td>\n",
       "      <td>-0.335284</td>\n",
       "      <td>0.261204</td>\n",
       "      <td>0.248297</td>\n",
       "      <td>0.821611</td>\n",
       "      <td>0.068742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351212</td>\n",
       "      <td>-0.547608</td>\n",
       "      <td>0.132004</td>\n",
       "      <td>0.211260</td>\n",
       "      <td>-0.712414</td>\n",
       "      <td>-0.196704</td>\n",
       "      <td>0.691225</td>\n",
       "      <td>0.953421</td>\n",
       "      <td>-0.792503</td>\n",
       "      <td>-0.611266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.211640</td>\n",
       "      <td>-0.646897</td>\n",
       "      <td>-1.211640</td>\n",
       "      <td>-1.299291</td>\n",
       "      <td>0.338244</td>\n",
       "      <td>-0.572816</td>\n",
       "      <td>-0.448466</td>\n",
       "      <td>-0.954318</td>\n",
       "      <td>-1.009791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564993</td>\n",
       "      <td>-0.547608</td>\n",
       "      <td>-1.077291</td>\n",
       "      <td>-0.919604</td>\n",
       "      <td>-0.612368</td>\n",
       "      <td>-1.199724</td>\n",
       "      <td>-1.257051</td>\n",
       "      <td>0.074083</td>\n",
       "      <td>-0.792503</td>\n",
       "      <td>-0.611266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result     FSP.1     FSW.1     SSP.1     SSW.1     ACE.1     DBF.1  \\\n",
       "0       1  0.119964 -0.088027 -0.119964 -0.374131 -0.672048  0.678214   \n",
       "1       1  2.303316 -0.181172 -2.303316 -0.744195 -1.008812 -1.406837   \n",
       "2       0 -0.486522 -1.205767  0.486522 -1.299291 -0.335284  0.678214   \n",
       "3       0 -0.001333 -1.112622  0.001333 -0.189099 -0.335284  0.261204   \n",
       "4       1  1.211640 -0.646897 -1.211640 -1.299291  0.338244 -0.572816   \n",
       "\n",
       "      WNR.1     UFE.1     BPC.1  ...     SSP.2     SSW.2     ACE.2     DBF.2  \\\n",
       "0 -0.050316 -1.220707  0.500154  ...  0.351212  0.329722 -1.077291 -0.542649   \n",
       "1 -0.846616 -0.687928  0.931567  ...  0.564993 -1.074005 -0.271094 -0.542649   \n",
       "2 -0.846616  0.555222 -1.225497  ...  0.671884 -0.196676  1.744396 -0.542649   \n",
       "3  0.248297  0.821611  0.068742  ...  0.351212 -0.547608  0.132004  0.211260   \n",
       "4 -0.448466 -0.954318 -1.009791  ...  0.564993 -0.547608 -1.077291 -0.919604   \n",
       "\n",
       "      WNR.2     UFE.2     BPC.2     BPW.2     NPA.2     NPW.2  \n",
       "0  0.288044 -0.505325  0.412900 -0.512142  2.136008  1.312970  \n",
       "1 -0.712414  0.806316 -0.422076 -0.805254 -0.155870 -0.759285  \n",
       "2 -0.712414 -1.585501 -0.143750  0.074083 -1.047156 -0.907303  \n",
       "3 -0.712414 -0.196704  0.691225  0.953421 -0.792503 -0.611266  \n",
       "4 -0.612368 -1.199724 -1.257051  0.074083 -0.792503 -0.611266  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0cfccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the explanatory variables from the response variable for the train set.\n",
    "Xtrain = train.iloc[:, 1:]\n",
    "ytrain = train['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482ee12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the explanatory variables from the response variable for the test set.\n",
    "Xtest = test.iloc[:, 1:]\n",
    "ytest = test['Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9f8c4",
   "metadata": {},
   "source": [
    "## Train the Model to predict winners of the match using the explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2aabdc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'random_state': 42}\n",
      "Best CV accuracy Score: 0.7782724505327245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Define the Parameters for the Decision Tree Model.\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],       # Split criterion ('gini' or 'entropy')\n",
    "    'max_depth': [3, 5, 10, 15],         # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],          # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['log2', 'sqrt'],       # Number of features to consider when looking for the best split\n",
    "    'random_state': [42]                    # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Load the Decision Tree model.\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# Create a Recall scoring function.\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Create a GridSearchCV instance.\n",
    "grid_search = GridSearchCV(classifier, param_grid, scoring=accuracy_scorer, cv=5)\n",
    "\n",
    "# Doing a grid search to get the best performing model.\n",
    "grid_search.fit(Xtrain.values, ytrain.values)\n",
    "\n",
    "# Get the parameters and recall score of the best performing model.\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy_scorer = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best CV accuracy Score:\", best_accuracy_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e57b6b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters found: {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n",
      "Best CV Accuracy Score: 0.9334094368340944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search for Logistic Regression.\n",
    "# Define the parameters for the model.\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],            # Regularization type ('l1' or 'l2')\n",
    "    'C': [0.01, 0.1, 1, 10, 100],       # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'saga'],    # Algorithm to use for optimization\n",
    "    'max_iter': [50, 100, 200, 300],        # Maximum number of iterations\n",
    "    'random_state': [42]                # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Load a Logistic Regression model.\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create a Recall scoring function.\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Create a GridSearchCV instance.\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring=accuracy_scorer)\n",
    "\n",
    "# Doing a grid search to get the best performing model.\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "# Get the best parameters and recall score of the best performing model.\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Show the results\n",
    "print(\"Best Hyperparameters found: \" + str(best_params))\n",
    "print(\"Best CV Accuracy Score: \" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21e10ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 'identity', 'alpha': 0.01, 'hidden_layer_sizes': 4, 'max_iter': 400, 'random_state': 42, 'solver': 'adam'}\n",
      "Best CV Recall Score: 0.9334474885844749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define the parameters for the MLP Model.\n",
    "param_grid = {\"hidden_layer_sizes\": [(2), (3), (4), (5), (10)], # we consider a small number for hidden layers as we have a small number of observations\n",
    "              \"activation\": ['identity', 'tanh', 'logistic', 'relu'],\n",
    "              \"solver\": ['adam', 'sgd'],\n",
    "              \"max_iter\": [100, 200, 400],\n",
    "              \"alpha\": [0.01, 0.001],\n",
    "              \"random_state\": [42]}\n",
    "\n",
    "# Specifying our Classifier.\n",
    "classifier = MLPClassifier()\n",
    "\n",
    "# Create a Recall scoring function.\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Create a GridSearchCV instance.\n",
    "grid_search = GridSearchCV(classifier, param_grid, scoring=accuracy_scorer, cv=5)\n",
    "\n",
    "# Using GridSearchCV to determine the best model.\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "# Get the best parameters and best F1 score\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best CV Recall Score:\", best_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "605e5746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.9, 'gamma': 0.1, 'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0, 'subsample': 0.8}\n",
      "Best CV Accuracy Score: 0.955593607305936\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the XGBoost regressor\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# Perform cross-validation grid search\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "# Using GridSearchCV to determine the best model.\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "# Get the best parameters and its Recall score.\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best CV Accuracy Score:\", best_accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1863ffb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy Score = 0.9120879120879121\n",
      "tp: 43 fn: 4 fp: 4 tn: 40\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us use the best hyperparameters for our XGBoost model.\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "model = xgb.XGBClassifier(colsample_bytree= 0.9, gamma=0.1, \n",
    "                          learning_rate= 0.3, max_depth= 5, n_estimators= 100, reg_alpha= 0.1, \n",
    "                          reg_lambda= 0, subsample= 0.8, random_state = 42)\n",
    "clf = model.fit(Xtrain, ytrain)\n",
    "\n",
    "# Make predictions using the model on the test set.\n",
    "y_pred = clf.predict(Xtest)\n",
    "\n",
    "# Calculate model performance such as F1, Recall, and Precision. \n",
    "from sklearn import metrics\n",
    "print(\"Test accuracy Score =\",metrics.accuracy_score(ytest, y_pred))\n",
    "\n",
    "# Define class labels.\n",
    "class_labels = np.unique(ytest)\n",
    "\n",
    "# Create a confusion matrix.\n",
    "cm = confusion_matrix(ytest, y_pred, labels=class_labels)\n",
    "\n",
    "# Proper labelling of outcomes.\n",
    "tp, fn, fp, tn= confusion_matrix(ytest, y_pred, labels=class_labels).ravel()\n",
    "print(\"tp:\", tp,\"fn:\", fn,\"fp:\",fp,\"tn:\", tn )\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3af395",
   "metadata": {},
   "source": [
    "## The XGBoost Model is observed to have a 0.91 classification accuracy. Furthermore, it performs well given the number of true positives and true negatives reflected in the confusion matrix. This will be the model that will be used to predict winners based on match play statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da3478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file for future use.\n",
    "with open('XGBoostWTennis.pkl', 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
